{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project: BERT classify the sentence whether contains software related words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import xmltodict\n",
    "import re\n",
    "import os\n",
    "from transformers import AutoTokenizer, AutoModel,AdamW\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader,WeightedRandomSampler\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score,f1_score\n",
    "from ignite.engine import Engine, Events\n",
    "from ignite.metrics import Accuracy, Loss, RunningAverage, Precision, Recall\n",
    "from ignite.handlers import ModelCheckpoint, EarlyStopping\n",
    "from ignite.contrib.handlers import ProgressBar\n",
    "from ignite.utils import manual_seed\n",
    "from ignite import metrics\n",
    "from ignite.metrics import precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#uncompress zip\n",
    "import zipfile\n",
    "with zipfile.ZipFile('unlabeled_data.zip', 'r') as zip_ref:\n",
    "    zip_ref.extractall('./')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xmipath='./train/'\n",
    "xmifilelist=os.listdir(xmipath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cleanxmifilelist=[]\n",
    "for x in xmifilelist:\n",
    "    if \".xmi\" in x:\n",
    "        Cleanxmifilelist.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transfer to json file\n",
    "for i in range(len(Cleanxmifilelist)):\n",
    "    temp=xmipath+Cleanxmifilelist[i]\n",
    "    with open(temp) as xml_file:\n",
    "        data_dict = xmltodict.parse(xml_file.read())\n",
    "        xml_file.close()\n",
    "        json_data = json.dumps(data_dict)\n",
    "        tempname=re.sub(\".xmi\",\".json\",Cleanxmifilelist[i])\n",
    "        temppath=\"./newTrain_json/\"\n",
    "        jsonpath=temppath+tempname\n",
    "        with open(jsonpath, \"w\") as json_file:\n",
    "            json_file.write(json_data)\n",
    "            json_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Token tool\n",
    "from nltk import word_tokenize\n",
    "from nltk.tokenize import MWETokenizer\n",
    "\n",
    "def multiword_tokenize(text, mwe):\n",
    "    # Initialize the MWETokenizer\n",
    "    protected_tuples = [word_tokenize(word) for word in mwe]\n",
    "    protected_tuples_underscore = ['_'.join(word) for word in protected_tuples]\n",
    "    tokenizer = MWETokenizer(protected_tuples)\n",
    "    # Tokenize the text.\n",
    "    tokenized_text = tokenizer.tokenize(word_tokenize(text))\n",
    "    # Replace the underscored protected words with the original MWE\n",
    "    for i, token in enumerate(tokenized_text):\n",
    "        if token in protected_tuples_underscore:\n",
    "            tokenized_text[i] = mwe[protected_tuples_underscore.index(token)]\n",
    "    return tokenized_text\n",
    "\n",
    "mwe = ['20-30', 'my bike']\n",
    "a=multiword_tokenize('Yes 20-30 minutes a day on my bike, it works great!!', mwe)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jsonpath='./newTrain_json/'\n",
    "jsonfilelist=os.listdir(jsonpath)\n",
    "jsonfilelist.remove('.ipynb_checkpoints')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jsonpathlist=[]\n",
    "for x in jsonfilelist:\n",
    "    jtemp=jsonpath+x\n",
    "    jsonpathlist.append(jtemp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test all\n",
    "import pandas as pd\n",
    "Alldf=pd.DataFrame(columns=['Docid', 'Sentencenumber', 'Sentence', 'Bilabel', 'SFname'])\n",
    "for x in jsonpathlist:\n",
    "    df=pd.DataFrame()\n",
    "    with open (x) as jsonfile:\n",
    "        jdata=json.load(jsonfile)\n",
    "        sfword=[]\n",
    "        Sentence=[]\n",
    "        Bilabel=[]\n",
    "        SFname=[]\n",
    "        Docid=[]\n",
    "        Fullsentence=[]\n",
    "        Sentencenumber=[]\n",
    "        if type(jdata['xmi:XMI']['typesystem:ClampNameEntityUIMA'])==dict:\n",
    "            begin=int(jdata['xmi:XMI']['typesystem:ClampNameEntityUIMA']['@begin'])\n",
    "            end=int(jdata['xmi:XMI']['typesystem:ClampNameEntityUIMA']['@end'])\n",
    "            sfword.append(jdata['xmi:XMI']['cas:Sofa'][\"@sofaString\"][begin:end])               \n",
    "        elif type(jdata['xmi:XMI']['typesystem:ClampNameEntityUIMA'])==list:\n",
    "            for i in range(len(jdata['xmi:XMI']['typesystem:ClampNameEntityUIMA'])):\n",
    "                begin=int(jdata['xmi:XMI']['typesystem:ClampNameEntityUIMA'][i]['@begin'])\n",
    "                end=int(jdata['xmi:XMI']['typesystem:ClampNameEntityUIMA'][i][\"@end\"])\n",
    "                sfword.append(jdata['xmi:XMI']['cas:Sofa'][\"@sofaString\"][begin:end])\n",
    "        sentences=jdata['xmi:XMI']['cas:Sofa'][\"@sofaString\"].split(\".\\n\")\n",
    "        for j in range(len(sentences)):\n",
    "            \n",
    "            tksentence=multiword_tokenize(sentences[j],sfword)\n",
    "            if len(list(set(tksentence) & set(sfword)))==0: \n",
    "                Bilabel.append(\"not software\")\n",
    "                SFname.append(\"\")\n",
    "            else:\n",
    "                Bilabel.append(\"software\")\n",
    "                sfinsentence=list(set(tksentence) & set(sfword))\n",
    "                sfstring=\",\".join(sfinsentence)\n",
    "                SFname.append(sfstring)\n",
    "            tkstring=\",\".join(tksentence)\n",
    "            Sentence.append(tkstring)\n",
    "            Fullsentence.append(\" \".join(tksentence))\n",
    "            idname=re.sub(\"./newTrain_json/\",\"\",x)\n",
    "            idname=re.sub(\".json\",\"\",idname)       \n",
    "            Docid.append(idname)\n",
    "            Sentencenumber.append(j)\n",
    "\n",
    "        df[\"Docid\"]=Docid\n",
    "        df[\"Docid\"]=df[\"Docid\"].astype(str)\n",
    "        df[\"Sentencenumber\"]=Sentencenumber\n",
    "        df[\"Sentencenumber\"]=df[\"Sentencenumber\"].astype(str)\n",
    "        df[\"Sentence\"]=Sentence\n",
    "        df[\"Bilabel\"]=Bilabel\n",
    "        df[\"SFname\"]=SFname\n",
    "        df[\"original_sent\"]=Fullsentence\n",
    "        df.drop(df[df['Sentence'] ==''].index, inplace = True)\n",
    "    \n",
    "    Alldf=Alldf.append(df,ignore_index=True)\n",
    "    \n",
    "Alldf['new_index']=Alldf['Docid']+Alldf['Sentencenumber']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Alldf['label']=np.where(Alldf['Bilabel']=='software',1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Alldf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and Validation Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inputs,validation_inputs= train_test_split(Alldf,random_state=999,test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindf=train_inputs[['new_index','original_sent','label']]\n",
    "validationdf=validation_inputs[['new_index','original_sent','label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create train label\n",
    "\n",
    "train_label={}\n",
    "\n",
    "for i in range(len(train_inputs)):\n",
    "    label=[]\n",
    "    index=train_inputs.new_index.values[i]\n",
    "    sfname=train_inputs.SFname.values[i]\n",
    "    if len(sfname)>0:\n",
    "        newsfname=sfname.split()\n",
    "        sfname=train_inputs.SFname.values[i].split()\n",
    "        tempsent=train_inputs.original_sent.values[i].split()\n",
    "        intlist=[0]*len(tempsent)\n",
    "        both = list(set(sfname).intersection(tempsent))\n",
    "        indices_B = [tempsent.index(x) for x in both]\n",
    "        for i in indices_B:\n",
    "            intlist[i]=1\n",
    "        label=intlist\n",
    "    elif len(sfname)==0:\n",
    "        label=[0]*len(train_inputs.original_sent.values[i].split())\n",
    "    train_label[index]=label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create train label\n",
    "\n",
    "train_label={}\n",
    "\n",
    "for i in range(len(train_inputs)):\n",
    "    label=[]\n",
    "    index=train_inputs.new_index.values[i]\n",
    "    sfname=train_inputs.SFname.values[i]\n",
    "    if len(sfname)>0:\n",
    "        newsfname=sfname.split()\n",
    "        sfname=train_inputs.SFname.values[i].split()\n",
    "        tempsent=train_inputs.original_sent.values[i].split()\n",
    "        intlist=[0]*len(tempsent)\n",
    "        both = list(set(sfname).intersection(tempsent))\n",
    "        indices_B = [tempsent.index(x) for x in both]\n",
    "        for i in indices_B:\n",
    "            intlist[i]=1\n",
    "        label=intlist\n",
    "    elif len(sfname)==0:\n",
    "        label=[0]*len(train_inputs.original_sent.values[i].split())\n",
    "    train_label[index]=label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Padding and Mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def paddingdict(input_dict,padingnumber,druglist):\n",
    "    length=[]\n",
    "    for i in input_dict.values():\n",
    "        length.append(len(i))\n",
    "    maxnu=np.max(length) \n",
    "    print(maxnu)\n",
    "    new_dict={}\n",
    "    new_dict_mask={}\n",
    "    for i in druglist:\n",
    "        value=input_dict.get(i)\n",
    "        new_dict_mask[i]=np.array([1]*len(value)+[0]*(maxnu-len(value))) \n",
    "        try:\n",
    "            if len(value)>0:\n",
    "                appendlist=[padingnumber]*(maxnu-len(value))\n",
    "                value=value+appendlist\n",
    "                new_dict[i]=np.array(value)\n",
    "        except:\n",
    "            value=[padingnumber]*maxnu\n",
    "            new_dict[i]=np.array(value)\n",
    "    return new_dict,new_dict_mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Vpaddingdict(input_dict,padingnumber,druglist):\n",
    "    length=[]\n",
    "    for i in input_dict.values():\n",
    "        length.append(len(i))\n",
    "    maxnu=384 \n",
    "    print(maxnu)\n",
    "    new_dict={}\n",
    "    new_dict_mask={}\n",
    "    for i in druglist:\n",
    "        value=input_dict.get(i)\n",
    "        new_dict_mask[i]=np.array([1]*len(value)+[0]*(maxnu-len(value)))\n",
    "        try:\n",
    "            if len(value)>0:\n",
    "                appendlist=[padingnumber]*(maxnu-len(value))\n",
    "                value=value+appendlist\n",
    "                new_dict[i]=np.array(value)\n",
    "        except:\n",
    "            value=[padingnumber]*maxnu\n",
    "            new_dict[i]=np.array(value)\n",
    "    return new_dict,new_dict_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train\n",
    "new_train_label_dict, new_train_label_dict_mask=paddingdict(train_label,0,list(train_label.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#validation\n",
    "new_validation_label_dict, new_validation_label_mask=Vpaddingdict(validation_label,0,list(validation_label.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class simpletrain(Dataset):\n",
    "    \"\"\"Face Landmarks dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, dataset,label_dict,label_dict_mask):\n",
    "        \"\"\"\n",
    "       \n",
    "        \"\"\"\n",
    "        self.data = dataset\n",
    "        self.label_dict=label_dict\n",
    "        self.label_dict_mask=label_dict_mask\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "\n",
    "        sentid= self.data.iloc[idx,0]\n",
    "        sent= self.data.iloc[idx,1]\n",
    "        sent_label= self.data.iloc[idx,2]\n",
    "        sent=self.tokenizer(sent,padding='max_length', truncation=True, max_length=384,return_tensors=\"pt\")\n",
    "       \n",
    "        \n",
    "        data=(sent,sent_label)\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class bert_rnn(nn.Module):\n",
    "    def __init__(self, args):\n",
    "        super(bert_rnn, self).__init__()\n",
    "        self.args = args\n",
    "        \n",
    "        self.emb=AutoModel.from_pretrained(self.args['modelname'])\n",
    "        self.emb_size=self.emb.config.hidden_size\n",
    "        self.lin1 = nn.Linear(self.emb_size, 2)\n",
    "        self.lin2 = nn.Linear(self.emb_size, self.args['num_labels'])\n",
    "        self.dropout = nn.Dropout(self.args['drop_out'])\n",
    "        \n",
    "    def forward(self,data1,mask1):\n",
    "        emb1 =self.emb(data1,mask1)\n",
    "        ner=self.lin1(torch.relu(self.dropout(emb1['last_hidden_state'])))\n",
    "        ner=torch.argmax(ner,2)\n",
    "        seq_class=self.lin2(torch.relu(self.dropout(emb1['pooler_output'])))\n",
    "        seq_class=torch.sigmoid(seq_class)\n",
    "        \n",
    "        return ner,seq_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config={'modelname':'bert-base-uncased',\n",
    "        'num_labels': 2,\n",
    "        'drop_out':0.2,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ignite Early stopping and check point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1234\n",
    "manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=simpletrain(traindf,new_train_label_dict, new_train_label_dict_mask)\n",
    "train_loader = DataLoader(train, batch_size=5, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation=simpletrain(validationdf,new_validation_label_dict, new_validation_label_mask)\n",
    "validation_loader = DataLoader(validation, batch_size=2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda=True\n",
    "device=3\n",
    "torch.cuda.set_device(device)\n",
    "model=bert_rnn(config)\n",
    "model.to(device)\n",
    "count_parameters(model)\n",
    "params=model.parameters()\n",
    "optimizer = AdamW(params,lr = 2e-5, eps = 1e-8 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss1 = nn.BCELoss()\n",
    "loss2= nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#early stoping\n",
    "def process_function(engine,batch):\n",
    "  \n",
    "    model.train()\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    sent,sent_label=batch\n",
    "   \n",
    "    sent_label=sent_label.to(device)\n",
    "    \n",
    "\n",
    "    \n",
    "    _,sent_pred=model(torch.squeeze(sent['input_ids']).to(device),torch.squeeze(sent['attention_mask']).to(device))\n",
    "    \n",
    "    \n",
    "    alloss=loss2(sent_pred,sent_label.long())\n",
    "    \n",
    "    \n",
    "    alloss.backward()\n",
    "    \n",
    "    optimizer.step()\n",
    "    \n",
    "    return alloss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluation for Early stopping\n",
    "def eval_function(engine,batch):\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        sent,sent_label=batch\n",
    "    \n",
    "        sent_label=sent_label.to(device)\n",
    "    \n",
    "        \n",
    "    \n",
    "        _,sent_pred=model(torch.squeeze(sent['input_ids']).to(device),torch.squeeze(sent['attention_mask']).to(device)) \n",
    "        \n",
    "        \n",
    "        sent_pred=torch.argmax(sent_pred,1).flatten()\n",
    "        \n",
    "        sent_label=sent_label.flatten()\n",
    "\n",
    "        return  sent_pred, sent_label\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Engine(process_function)\n",
    "validation_evaluator = Engine(eval_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RunningAverage(output_transform=lambda x: x).attach(trainer, 'loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def thresholded_output_transform_1(output):\n",
    "    y_1, y_2= output\n",
    "    \n",
    "    return y_1, y_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Precision(output_transform=thresholded_output_transform_1).attach(validation_evaluator, 'sen_precision')\n",
    "Recall(output_transform=thresholded_output_transform_1).attach(validation_evaluator, 'sen_recall')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_function(engine):\n",
    "    val_loss = engine.state.metrics['sen_precision']\n",
    "    return val_loss\n",
    "handler = EarlyStopping(patience=5, score_function=score_function, trainer=trainer)\n",
    "validation_evaluator.add_event_handler(Events.COMPLETED, handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@trainer.on(Events.EPOCH_COMPLETED)\n",
    "def log_validation_results(engine):\n",
    "    validation_evaluator.run(validation_loader)\n",
    "    metrics = validation_evaluator.state.metrics\n",
    "    sen_precision=metrics['sen_precision']\n",
    "    sen_recall=metrics['sen_recall']\n",
    "    print(sen_precision, sen_recall)\n",
    "    pbar.log_message(\n",
    "        \"Validation Results - Epoch: {}  Sen_precision: {:.2f} Sen_Recall : {:.2f} \".format(engine.state.epoch,sen_precision,sen_recall))# seg_precision, , seq_recall#Seg_recall: {:.2f}, Seg_precision: {:.2f}\n",
    "    pbar.n = pbar.last_print_n = 0\n",
    "\n",
    "trainer.add_event_handler(Events.EPOCH_COMPLETED, log_validation_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pbar = ProgressBar(persist=True, bar_format=\"\")\n",
    "pbar.attach(trainer, ['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pbar = ProgressBar(persist=True, bar_format=\"\")\n",
    "pbar.attach(trainer, ['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.run(train_loader, max_epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_evaluator.run(validation_loader)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3a87b1261c0ef58c5031f845928eb35316ce12606aaccb63580aec5f268f8382"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8rc1 ('my_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
